# -*- coding: utf-8 -*-
"""NLP_CW2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17J6gvzh3hFJ6P0mpOzbAJbEBzRTRTda0

**Install and import needed Libraries**
"""

!pip install -U accelerate

!pip install transformers tokenizers
!pip install datasets

!pip install emoji

from datasets import Dataset
import torch
from transformers import BertTokenizerFast, BertForSequenceClassification, TrainingArguments, Trainer, RobertaTokenizerFast, RobertaForSequenceClassification
from transformers import AutoTokenizer, AutoModelForSequenceClassification
from sklearn.model_selection import train_test_split
from sklearn.utils.class_weight import compute_class_weight
from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score
import pandas as pd
import numpy as np
import os
from sklearn.metrics import accuracy_score, precision_recall_fscore_support
from torch.utils.data import WeightedRandomSampler
from google.colab import files
from torch import nn
from collections import Counter
import emoji
import re
from transformers import pipeline
from tqdm import tqdm
import random
from transformers import EarlyStoppingCallback
import plotly.graph_objects as go
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.utils import resample

uploaded = files.upload('olid-training-v1.0.tsv')

"""# EDA

**Code for data exploration**
"""

df = pd.read_csv("olid-training-v1.0.tsv/olid-training-v1.0.tsv", sep="\t")

subtask_a_counts = df['subtask_a'].value_counts()
subtask_b_counts = df[df['subtask_a'] == 'OFF']['subtask_b'].value_counts()
subtask_c_counts = df[df['subtask_b'] == 'TIN']['subtask_c'].value_counts()
print(subtask_a_counts)
print(subtask_b_counts)
print(subtask_c_counts)

plt.figure(figsize=(18, 6))

plt.subplot(1, 3, 1)
sns.barplot(x=subtask_a_counts.index, y=subtask_a_counts.values, palette="Blues_d")
plt.title("Subtask A: Offensive vs Not Offensive")
plt.xlabel("Category")
plt.ylabel("Count")

plt.subplot(1, 3, 2)
sns.barplot(x=subtask_b_counts.index, y=subtask_b_counts.values, palette="Oranges_d")
plt.title("Subtask B: Targeted vs Not Targeted\n(Offensive tweets only)")
plt.xlabel("Category")
plt.ylabel("Count")

plt.subplot(1, 3, 3)
sns.barplot(x=subtask_c_counts.index, y=subtask_c_counts.values, palette="Greens_d")
plt.title("Subtask C: Individual, Group, Other\n(Targeted tweets only)")
plt.xlabel("Category")
plt.ylabel("Count")

plt.tight_layout()
plt.show()

"""# New Section"""

!accelerate config default

os.environ["ACCELERATE_USE_FP16"] = "true"  # Enables mixed precision
os.environ["ACCELERATE_MULTI_GPU"] = "true"

"""# BERT base

**Load and split data**
"""

df = pd.read_csv("olid-training-v1.0.tsv/olid-training-v1.0.tsv", sep="\t")[["tweet", "subtask_a"]]
label_map = {"NOT": 0, "OFF": 1}
df["label"] = df["subtask_a"].map(label_map)

train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)
train_dataset = Dataset.from_pandas(train_df)
val_dataset = Dataset.from_pandas(val_df)

"""**Tokenize data**"""

# Tokenizer
tokenizer = BertTokenizerFast.from_pretrained("bert-base-uncased")

def tokenize(example):
    return tokenizer(example["tweet"])

train_dataset = train_dataset.map(tokenize, batched=True)
val_dataset = val_dataset.map(tokenize, batched=True)

# Set format for PyTorch
train_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])
val_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])

"""**Load Model**"""

# Model
model = BertForSequenceClassification.from_pretrained("bert-base-uncased", num_labels=2)

"""**Define the metrics needed from trainer**"""

def compute_metrics(eval_pred):
    logits, labels = eval_pred
    predictions = np.argmax(logits, axis=-1)

    precision, recall, f1, _ = precision_recall_fscore_support(
        labels,
        predictions,
        average="weighted"
    )
    acc = accuracy_score(labels, predictions)

    return {
        "accuracy": acc,
        "precision": precision,
        "recall": recall,
        "f1": f1,
    }

"""**Define Training Arguments**"""

# Training args
training_args = TrainingArguments(
    output_dir="./bert-offense-detector",
    evaluation_strategy="epoch",
    save_strategy="epoch",
    learning_rate=2e-5,
    per_device_train_batch_size=16,
    per_device_eval_batch_size=16,
    num_train_epochs=3,
    weight_decay=0.01,
    logging_dir='./logs',
)

"""**Create trainer**"""

# Trainer
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=val_dataset,
    tokenizer=tokenizer,
    compute_metrics=compute_metrics,
)

"""**Run trainer**"""

# Train

trainer.train()

"""**Print results**"""

# Evaluate
results = trainer.evaluate()
print(results)

"""**The method for subtask b is the same as subtask a**"""

df_2 = pd.read_csv("olid-training-v1.0.tsv/olid-training-v1.0.tsv", sep="\t")[["tweet", "subtask_a","subtask_b"]]
df_2 = df_2[df_2["subtask_a"] == "OFF"].copy()
df_2["subtask_b"].fillna("NONE", inplace=True)  # Assign "NONE" to missing values in subtask_b

label_map = {"NOT": 0, "OFF": 1}
df_2["label"] = df_2["subtask_a"].map(label_map)
label_map_b = {"TIN": 0, "UNT": 1}
df_2["label"] = df_2["subtask_b"].map(label_map_b)

train_df_2, val_df_2 = train_test_split(df_2, test_size=0.2, random_state=42)
train_dataset_2 = Dataset.from_pandas(train_df_2)
val_dataset_2 = Dataset.from_pandas(val_df_2)

# Tokenizer
tokenizer = BertTokenizerFast.from_pretrained("bert-base-uncased")

def tokenize(example):
    return tokenizer(example["tweet"])

train_dataset_2 = train_dataset_2.map(tokenize, batched=True)
val_dataset_2 = val_dataset_2.map(tokenize, batched=True)

# Set format for PyTorch
train_dataset_2.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])
val_dataset_2.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])

def compute_metrics(eval_pred):
    logits, labels = eval_pred
    predictions = np.argmax(logits, axis=-1)

    precision, recall, f1, _ = precision_recall_fscore_support(
        labels,
        predictions,
        average="weighted"
    )
    acc = accuracy_score(labels, predictions)

    return {
        "accuracy": acc,
        "precision": precision,
        "recall": recall,
        "f1": f1,
    }

model_stage2 = BertForSequenceClassification.from_pretrained("bert-base-uncased", num_labels=2)

training_args_stage2 = TrainingArguments(
    output_dir="./bert_stage2_targeted",
    evaluation_strategy="epoch",
    learning_rate=2e-5,
    per_device_train_batch_size=16,
    per_device_eval_batch_size=16,
    num_train_epochs=3,
    weight_decay=0.01,
    logging_dir="./logs_stage2",
    fp16=torch.cuda.is_available()
)

trainer_stage2 = Trainer(
    model=model_stage2,
    args=training_args_stage2,
    train_dataset=train_dataset_2,
    eval_dataset=val_dataset_2,
    tokenizer=tokenizer,
    compute_metrics=compute_metrics,
)

trainer_stage2.train()

results_stage2 = trainer_stage2.evaluate()
print("ðŸ”Ž Stage 2 Evaluation:", results_stage2)

def tokenize_function_c(examples):
    tokenized = tokenizer(examples["tweet"], truncation=True, padding="max_length")
    tokenized["label"] = examples["label"]
    return tokenized

"""**The code for subtask c is similar to a and b, but with 3 classes instead**"""

df_3 = pd.read_csv("olid-training-v1.0.tsv/olid-training-v1.0.tsv", sep="\t")[["tweet", "subtask_a","subtask_b","subtask_c"]]
df_3 = df_3[df_3["subtask_b"] == "TIN"].copy()
df_3["subtask_c"].fillna("NONE", inplace=True)  # Assign "NONE" to missing values in subtask_b

label_map_c = {"IND": 0, "GRP": 1, "OTH": 2}
df_3["label"] = df_3["subtask_c"].map(label_map_c)

train_df_3, val_df_3 = train_test_split(df_3, test_size=0.2, random_state=42)
train_dataset_3 = Dataset.from_pandas(train_df_3)
val_dataset_3 = Dataset.from_pandas(val_df_3)

# Tokenizer
tokenizer = BertTokenizerFast.from_pretrained("bert-base-uncased")

def tokenize(example):
    return tokenizer(example["tweet"])

train_dataset_3 = train_dataset_3.map(tokenize, batched=True)
val_dataset_3 = val_dataset_3.map(tokenize, batched=True)

# Set format for PyTorch
train_dataset_3.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])
val_dataset_3.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])

"""**Number of labels increased to 3**"""

model_stage3 = BertForSequenceClassification.from_pretrained("bert-base-uncased", num_labels=3)

def compute_metrics(eval_pred):
    logits, labels = eval_pred
    predictions = np.argmax(logits, axis=-1)

    precision, recall, f1, _ = precision_recall_fscore_support(
        labels,
        predictions,
        average="weighted"
    )
    acc = accuracy_score(labels, predictions)

    return {
        "accuracy": acc,
        "precision": precision,
        "recall": recall,
        "f1": f1,
    }

training_args_stage3 = TrainingArguments(
    output_dir="./bert_stage3_target_type",
    evaluation_strategy="epoch",
    learning_rate=2e-5,
    per_device_train_batch_size=16,
    per_device_eval_batch_size=16,
    num_train_epochs=3,
    weight_decay=0.01,
    logging_dir="./logs_stage3",
    fp16=torch.cuda.is_available()
)

trainer_stage3 = Trainer(
    model=model_stage3,
    args=training_args_stage3,
    train_dataset=train_dataset_3,
    eval_dataset=val_dataset_3,
    tokenizer=tokenizer,
    compute_metrics=compute_metrics,
)

trainer_stage3.train()

results_stage3 = trainer_stage3.evaluate()
print("ðŸ”Ž Stage 3 Evaluation:", results_stage3)

"""# BERT Tweet

**The code for the BERTweet section is similar to the BERT section, with minor changes**
"""

df_4 = pd.read_csv("olid-training-v1.0.tsv/olid-training-v1.0.tsv", sep="\t")[["tweet", "subtask_a"]]
label_map_a = {"OFF": 1, "NOT": 0}
df_4["label"] = df_4["subtask_a"].map(label_map_a)

train_df_4, val_df_4 = train_test_split(df_4, test_size=0.2, random_state=42)
train_dataset_4 = Dataset.from_pandas(train_df_4)
val_dataset_4 = Dataset.from_pandas(val_df_4)

"""**Tokenizer is now BERTweet**"""

# Tokenizer
tokenizer = AutoTokenizer.from_pretrained("vinai/bertweet-large", use_fast=False)

def tokenize(example):
    return tokenizer(example["tweet"])

train_dataset_4 = train_dataset_4.map(tokenize, batched=True)
val_dataset_4 = val_dataset_4.map(tokenize, batched=True)

# Set format for PyTorch
train_dataset_4.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])
val_dataset_4.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])

"""**Model is now BERTweet**"""

model_stage4 = AutoModelForSequenceClassification.from_pretrained("vinai/bertweet-large", num_labels=2)

training_args_4 = TrainingArguments(
    output_dir="./bertweet_stage1_offensiveness",
    evaluation_strategy="epoch",
    learning_rate=2e-5,
    per_device_train_batch_size=32,
    per_device_eval_batch_size=32,
    num_train_epochs=3,
    weight_decay=0.01,
    logging_dir="./logs_stage1_bt",
    fp16=torch.cuda.is_available()
)

def compute_metrics(eval_pred):
    logits, labels = eval_pred
    predictions = np.argmax(logits, axis=-1)

    precision, recall, f1, _ = precision_recall_fscore_support(
        labels,
        predictions,
        average="weighted"
    )
    acc = accuracy_score(labels, predictions)

    return {
        "accuracy": acc,
        "precision": precision,
        "recall": recall,
        "f1": f1,
    }

trainer_stage4 = Trainer(
    model=model_stage4,
    args=training_args_4,
    train_dataset=train_dataset_4,
    eval_dataset=val_dataset_4,
    tokenizer=tokenizer,
    compute_metrics=compute_metrics
)

trainer_stage4.train()

results_4 = trainer_stage4.evaluate()
print("ðŸ“Š Stage 1 (BERTweet) Results:", results_4)

df_5 = pd.read_csv("olid-training-v1.0.tsv/olid-training-v1.0.tsv", sep="\t")[["tweet", "subtask_a", "subtask_b"]]
df_5 = df_5[df_5["subtask_a"] == "OFF"].copy()
df_5["subtask_b"].fillna("NONE", inplace=True)

label_map_b = {"TIN": 0, "UNT": 1}
df_5["label"] = df_5["subtask_b"].map(label_map_b)

train_df_5, val_df_5 = train_test_split(df_5, test_size=0.2, random_state=42)
train_dataset_5 = Dataset.from_pandas(train_df_5)
val_dataset_5 = Dataset.from_pandas(val_df_5)

# Tokenizer
tokenizer = AutoTokenizer.from_pretrained("vinai/bertweet-large", use_fast=False)

def tokenize(example):
    return tokenizer(example["tweet"])

train_dataset_5 = train_dataset_5.map(tokenize, batched=True)
val_dataset_5 = val_dataset_5.map(tokenize, batched=True)

# Set format for PyTorch
train_dataset_5.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])
val_dataset_5.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])

model_stage5 = AutoModelForSequenceClassification.from_pretrained("vinai/bertweet-large", num_labels=2)

training_args_5 = TrainingArguments(
    output_dir="./bertweet_stage2_targeted",
    evaluation_strategy="epoch",
    learning_rate=2e-5,
    per_device_train_batch_size=16,
    per_device_eval_batch_size=16,
    num_train_epochs=3,
    weight_decay=0.01,
    logging_dir="./logs_stage2_bt",
    fp16=torch.cuda.is_available()
)

trainer_stage5 = Trainer(
    model=model_stage5,
    args=training_args_5,
    train_dataset=train_dataset_5,
    eval_dataset=val_dataset_5,
    tokenizer=tokenizer,
    compute_metrics=compute_metrics
)

trainer_stage5.train()

results_5 = trainer_stage5.evaluate()
print("ðŸ“Š Stage 2 (BERTweet) Results:", results_5)

df_6 = pd.read_csv("olid-training-v1.0.tsv/olid-training-v1.0.tsv", sep="\t")[["tweet", "subtask_a", "subtask_b", "subtask_c"]]
df_6["subtask_c"].fillna("NONE", inplace=True)  # Fill NAs
df_6 = df_6[df_6["subtask_b"] == "TIN"].copy()  # Only TIN tweets

label_map_c = {"IND": 0, "GRP": 1, "OTH": 2}
df_6["label"] = df_6["subtask_c"].map(label_map_c)

train_df_6, val_df_6 = train_test_split(df_6, test_size=0.2, random_state=42)
train_dataset_6 = Dataset.from_pandas(train_df_6)
val_dataset_6 = Dataset.from_pandas(val_df_6)

# Tokenizer
tokenizer = AutoTokenizer.from_pretrained("vinai/bertweet-large", use_fast=False)

def tokenize(example):
    return tokenizer(example["tweet"], padding="max_length", truncation=True, max_length=128)

train_dataset_6 = train_dataset_6.map(tokenize, batched=True)
val_dataset_6 = val_dataset_6.map(tokenize, batched=True)

# Set format for PyTorch
train_dataset_6.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])
val_dataset_6.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])

model_stage6 = AutoModelForSequenceClassification.from_pretrained("vinai/bertweet-large", num_labels=3)

training_args_6 = TrainingArguments(
    output_dir="./bertweet_stage3",
    evaluation_strategy="epoch",
    learning_rate=2e-5,
    per_device_train_batch_size=16,
    per_device_eval_batch_size=16,
    num_train_epochs=3,
    weight_decay=0.01,
    logging_dir="./logs_bertweet_stage3",
    fp16=torch.cuda.is_available()
)

def compute_metrics(eval_pred):
    logits, labels = eval_pred
    predictions = np.argmax(logits, axis=-1)

    precision, recall, f1, _ = precision_recall_fscore_support(
        labels,
        predictions,
        average="weighted"
    )
    acc = accuracy_score(labels, predictions)

    return {
        "accuracy": acc,
        "precision": precision,
        "recall": recall,
        "f1": f1,
    }

trainer_stage6 = Trainer(
    model=model_stage6,
    args=training_args_6,
    train_dataset=train_dataset_6,
    eval_dataset=val_dataset_6,
    tokenizer=tokenizer,
    compute_metrics=compute_metrics
)

trainer_stage6.train()

results_6 = trainer_stage6.evaluate()
print("ðŸ“Š BERTweet Stage 3 Results:", results_6)

"""# RoBERTa

**Subtask a**
"""

df_7 = pd.read_csv("olid-training-v1.0.tsv/olid-training-v1.0.tsv", sep="\t")[["tweet", "subtask_a"]]
label_map_7 = {"OFF": 0, "NOT": 1}
df_7["label"] = df_7["subtask_a"].map(label_map_7)

test_texts = df_7["tweet"].tolist()
test_labels = df_7["label"].tolist()

class_names = ["offensive tweet", "not offensive tweet"]  # Mapped from OFF and NOT

olid_dataset = {
    "name": "OLID-Offensive Classification",
    "test_texts": test_texts,
    "test_labels": test_labels,
    "class_names": class_names,
}

"""**Define the function for running the roberta model for subtask a**"""

def evaluate_huggingface(dataset, model="roberta"):
    if model == "base":
        classifier = pipeline("zero-shot-classification", device=0)
    else:
        classifier = pipeline("zero-shot-classification", model="roberta-large-mnli", device=0)

    correct = 0
    predictions, gold_labels = [], []

    for text, gold_label_idx in tqdm(zip(dataset["test_texts"], dataset["test_labels"]), total=len(dataset["test_texts"])):
        result = classifier(text, dataset["class_names"], multi_label=False)
        predicted_label = result["labels"][0]
        gold_label = dataset["class_names"][gold_label_idx]

        predictions.append(predicted_label)
        gold_labels.append(gold_label)

        if predicted_label == gold_label:
            correct += 1

    accuracy = correct / len(predictions)
    return accuracy

"""**Run function**"""

print("Running RoBERTa zero-shot classification on OLID...")
acc_roberta = evaluate_huggingface(olid_dataset, model="roberta")
print("âœ… RoBERTa Accuracy (Zero-Shot, Renamed Classes):", acc_roberta)

"""**Subtask b**"""

# Stage 2 Data Prep
df_8 = pd.read_csv("olid-training-v1.0.tsv/olid-training-v1.0.tsv", sep="\t")
df_8 = df_8[df_8["subtask_a"] == "OFF"].dropna(subset=["subtask_b"])
label_map_8 = {"UNT": 0, "TIN": 1}
df_8["label"] = df_8["subtask_b"].map(label_map_8)

stage2_class_names = ["untargeted offense", "targeted offense"]

test_texts2 = df_8["tweet"].tolist()
test_labels2 = df_8["label"].tolist()

stage2_dataset = {
    "name": "OLID-Targeted Offense Classification",
    "test_texts": test_texts2,
    "test_labels": test_labels2,
    "class_names": stage2_class_names,
}

print("\nRunning RoBERTa zero-shot classification on OLID Stage 2...")
acc_stage2 = evaluate_huggingface(stage2_dataset, model="roberta")
print("âœ… RoBERTa Accuracy (Zero-Shot, Renamed Classes - Stage 2):", acc_stage2)

"""**Subtask c**"""

# Stage 3 Data Prep
df_9 = pd.read_csv("olid-training-v1.0.tsv/olid-training-v1.0.tsv", sep="\t")
df_9 = df_9[df_9["subtask_b"] == "TIN"].dropna(subset=["subtask_c"])
label_map_9 = {"IND": 0, "GRP": 1, "OTH": 2}
df_9["label"] = df_9["subtask_c"].map(label_map_9)

stage3_class_names = ["targeted at individual", "targeted at group", "targeted at other"]

train_texts3, test_texts3, train_labels3, test_labels3 = train_test_split(
    df_9["tweet"].tolist(), df_9["label"].tolist(), test_size=0.2, random_state=42
)

stage3_dataset = {
    "name": "OLID-Offense Type Classification",
    "test_texts": test_texts3,
    "test_labels": test_labels3,
    "class_names": stage3_class_names,
}

print("\nRunning RoBERTa zero-shot classification on OLID Stage 3...")
acc_stage3 = evaluate_huggingface(stage3_dataset, model="roberta")
print("âœ… RoBERTa Accuracy (Zero-Shot, Renamed Classes - Stage 3):", acc_stage3)